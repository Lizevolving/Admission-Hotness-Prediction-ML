# -*- coding: utf-8 -*-
"""
è®­ç»ƒè„šæœ¬
ç›®æ ‡ï¼šå¿«é€Ÿè®­ç»ƒä¸€ä¸ªç¨³å¥çš„æ¨¡å‹ï¼Œå¯å¤ç°ï¼Œå¯è§£é‡Šã€‚
æµç¨‹ï¼šè¯»å–æ•°æ® â†’ å¤„ç†ç‰¹å¾ â†’ æ£€æŸ¥æ•°æ®æ³„éœ² â†’ äº¤å‰éªŒè¯ â†’ æœ€ç»ˆè®­ç»ƒ â†’ è¾“å‡ºç»“æœ
"""

import os
import json
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import joblib

from sklearn.ensemble import RandomForestRegressor
from sklearn.dummy import DummyRegressor
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.inspection import permutation_importance

# ä» config.py å¯¼å…¥é…ç½®ï¼ˆä¿æŒ config ä¸å˜ï¼‰
from config import (
    DATA_PATH, MODEL_PATH, COLUMNS_PATH,
    TARGET_COLUMN, MODEL_PARAMS
)

RANDOM_STATE = 42
CV_FOLDS = 5
LEAKAGE_CORR_THRESHOLD = 0.85 # æ•°å€¼ç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§è¶…è¿‡æ­¤é˜ˆå€¼æ—¶ï¼Œè®¤ä¸ºå¯èƒ½æ³„éœ²ï¼Œä¼šè‡ªåŠ¨ç§»é™¤


def load_data(path):
    print(f"æ­£åœ¨åŠ è½½æ•°æ®: {path}")
    df = pd.read_csv(path)
    print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œæ•°æ®ç»´åº¦: {df.shape}")
    return df


def feature_engineering(df):
    """
    ç‰¹å¾å¤„ç†ï¼ˆç®€å•é€æ˜ï¼‰ï¼š
    1. å¯¹éƒ¨åˆ†æ•°å€¼åš log è½¬æ¢ï¼Œå‡å°‘æç«¯å€¼å½±å“
    2. å¯¹ç±»åˆ«å˜é‡åš one-hotï¼ˆåªä¿ç•™å¿…è¦çš„ä¿¡æ¯ï¼‰
    3. åˆ é™¤è®­ç»ƒç”¨ä¸åˆ°çš„åŸå§‹åˆ—ï¼Œå‡å°‘å™ªéŸ³
    """
    print("å¼€å§‹å¤„ç†ç‰¹å¾...")
    df_proc = df.copy()

    # log è½¬æ¢ï¼ˆé¿å…æç«¯æ•°å€¼å½±å“æ¨¡å‹ï¼‰
    for col in ['plan_quota', 'apply_num', 'min_score_rank']:
        if col in df_proc.columns:
            df_proc[f'log_{col}'] = np.log1p(df_proc[col])

    # one-hot ç¼–ç ï¼ˆæŠŠæ–‡å­—å˜æˆæ¨¡å‹å¯è¯†åˆ«çš„æ•°å­—ï¼‰
    categorical_features = [c for c in ['province', 'school_tier', 'category'] if c in df_proc.columns]
    df_encoded = pd.get_dummies(df_proc, columns=categorical_features, drop_first=True)

    # åˆ é™¤è®­ç»ƒä¸­ä¸éœ€è¦çš„å­—æ®µï¼ˆå¦‚åç§°ç±»æ–‡æœ¬ï¼‰
    remove_candidates = ['school_name', 'major_name', 'plan_quota', 'apply_num', 'min_score_rank']
    for c in remove_candidates:
        if c in df_encoded.columns:
            df_encoded = df_encoded.drop(columns=c)

    # ç¡®ä¿ç›®æ ‡åˆ—ä¸å­˜åœ¨äºç‰¹å¾è¡¨ä¸­ï¼ˆé¿å…ä¿¡æ¯æ³„éœ²ï¼‰
    if TARGET_COLUMN in df_encoded.columns:
        df_encoded = df_encoded.drop(columns=[TARGET_COLUMN])

    print(f"ç‰¹å¾å¤„ç†å®Œæˆï¼Œå…± {df_encoded.shape[1]} ä¸ªç‰¹å¾")
    return df_proc, df_encoded


def leakage_check_and_drop(df_proc, df_encoded):
    """
    æ£€æŸ¥æ˜¯å¦æœ‰ä¸ç›®æ ‡é«˜åº¦ç›¸å…³çš„æ•°å€¼ç‰¹å¾ï¼ˆ> é˜ˆå€¼ï¼‰ï¼Œé¿å…â€œæå‰çŸ¥é“ç­”æ¡ˆâ€å¯¼è‡´ä½œå¼Šæ•ˆæœã€‚
    å¦‚æœå‘ç°ï¼Œåˆ™è‡ªåŠ¨ç§»é™¤ã€‚
    """
    print("æ£€æŸ¥ç‰¹å¾ä¸ç›®æ ‡çš„ç›¸å…³æ€§ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰...")

    if TARGET_COLUMN not in df_proc.columns:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡åˆ—ï¼Œè·³è¿‡æ³„éœ²æ£€æŸ¥")
        return df_encoded, []

    numeric_cols = df_proc.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if c != TARGET_COLUMN]
    corr = df_proc[numeric_cols + [TARGET_COLUMN]].corr()[TARGET_COLUMN].drop(TARGET_COLUMN).abs().sort_values(ascending=False)

    to_drop = []
    for feat, corr_val in corr.items():
        if corr_val >= LEAKAGE_CORR_THRESHOLD:
            print(f"âš ï¸ ç‰¹å¾è¿‡äºæ¥è¿‘ç­”æ¡ˆï¼ˆå¯èƒ½æ³„éœ²ï¼‰: {feat} ä¸ {TARGET_COLUMN} çš„ç›¸å…³æ€§ä¸º {corr_val:.3f}ï¼Œå·²è‡ªåŠ¨ç§»é™¤ã€‚")
            for c in [feat, f'log_{feat}']:
                if c in df_encoded.columns:
                    df_encoded = df_encoded.drop(columns=[c])
                    to_drop.append(c)

    if not to_drop:
        print(f"æœªå‘ç°ç›¸å…³æ€§è¶…è¿‡ {LEAKAGE_CORR_THRESHOLD} çš„ç‰¹å¾ã€‚")

    return df_encoded, to_drop


def evaluate_cv_baseline(model, X, y, cv=CV_FOLDS):
    """
    ç”¨ KFold åšäº¤å‰éªŒè¯ï¼Œçœ‹æ¨¡å‹åœ¨ä¸åŒæ•°æ®åˆ†ç‰‡ä¸Šçš„è¡¨ç°æ˜¯å¦ç¨³å®šã€‚
    åŒæ—¶å¯¹æ¯”ä¸€ä¸ªâ€œä»€ä¹ˆéƒ½ä¸åšçš„åŸºçº¿æ¨¡å‹â€ï¼ˆé¢„æµ‹å¹³å‡å€¼ï¼‰ã€‚
    """
    print(f"æ­£åœ¨è¿›è¡Œ {cv} æŠ˜äº¤å‰éªŒè¯ (RÂ²)...")
    kf = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)

    scores = cross_val_score(model, X, y, cv=kf, scoring='r2')
    baseline = DummyRegressor(strategy='mean')
    baseline_scores = cross_val_score(baseline, X, y, cv=kf, scoring='r2')

    print(f"æ¨¡å‹ RÂ² å¹³å‡å€¼: {scores.mean():.4f}  æ ‡å‡†å·®: {scores.std():.4f}")
    print(f"åŸºçº¿ï¼ˆé¢„æµ‹å¹³å‡å€¼ï¼‰RÂ²: {baseline_scores.mean():.4f}  æ ‡å‡†å·®: {baseline_scores.std():.4f}")
    return scores, baseline_scores


def train_final_and_evaluate(model, X_train, y_train, X_test, y_test):
    print("æ­£åœ¨è®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼Œå¹¶è¯„ä¼°æµ‹è¯•é›†...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print("æµ‹è¯•é›†ç»“æœï¼š")
    print(f"  MSE:  {mse:.4f}")
    print(f"  RMSE: {rmse:.4f}")
    print(f"  MAE:  {mae:.4f}")
    print(f"  RÂ²:   {r2:.4f}")

    return {
        'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2, 'y_pred': y_pred
    }


def permutation_importance_report(model, X_test, y_test, n_repeats=20):
    print("æ­£åœ¨è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆç½®æ¢é‡è¦æ€§ï¼‰...")
    res = permutation_importance(model, X_test, y_test, n_repeats=n_repeats, random_state=RANDOM_STATE, n_jobs=-1)

    imp_df = pd.DataFrame({
        'feature': X_test.columns,
        'perm_importance_mean': res.importances_mean,
        'perm_importance_std': res.importances_std
    }).sort_values('perm_importance_mean', ascending=False)

    print("\næœ€é‡è¦çš„å‰ 10 ä¸ªç‰¹å¾ï¼š")
    for _, r in imp_df.head(10).iterrows():
        print(f"  {r['feature']}: mean={r['perm_importance_mean']:.4f} std={r['perm_importance_std']:.4f}")

    return imp_df


def save_artifacts(model, feature_columns, metrics, out_model_path=MODEL_PATH, out_columns_path=COLUMNS_PATH, out_metrics_path=None):
    os.makedirs(Path(out_model_path).parent, exist_ok=True)
    os.makedirs(Path(out_columns_path).parent, exist_ok=True)

    joblib.dump(model, out_model_path)
    joblib.dump(feature_columns, out_columns_path)

    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {out_model_path}")
    print(f"âœ… ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜: {out_columns_path}")

    if out_metrics_path:
        with open(out_metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜: {out_metrics_path}")


def main():
    print("=" * 50)
    print("å¼€å§‹æ‰§è¡Œè®­ç»ƒæµç¨‹")
    print("=" * 50)

    df = load_data(DATA_PATH)

    df_proc, df_encoded = feature_engineering(df)

    df_encoded, dropped_features = leakage_check_and_drop(df_proc, df_encoded)

    if TARGET_COLUMN not in df.columns:
        raise ValueError(f"æ‰¾ä¸åˆ°ç›®æ ‡åˆ—: {TARGET_COLUMN}")

    X = df_encoded.copy()
    y = df[TARGET_COLUMN].copy()

    if X.shape[0] != y.shape[0]:
        raise ValueError("X ä¸ y çš„è¡Œæ•°ä¸ä¸€è‡´ï¼Œè¯·æ£€æŸ¥æ•°æ®ã€‚")

    rf = RandomForestRegressor(**MODEL_PARAMS)

    scores, baseline_scores = evaluate_cv_baseline(rf, X, y, cv=CV_FOLDS)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    print(f"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")

    final_metrics = train_final_and_evaluate(rf, X_train, y_train, X_test, y_test)

    perm_imp_df = permutation_importance_report(rf, X_test, y_test, n_repeats=20)

    feat_imp = pd.DataFrame({
        'feature': X.columns,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)

    metrics_to_save = {
        'cv_r2_mean': float(scores.mean()), 'cv_r2_std': float(scores.std()),
        'baseline_cv_r2_mean': float(baseline_scores.mean()), 'baseline_cv_r2_std': float(baseline_scores.std()),
        'test_metrics': {k: float(v) for k, v in final_metrics.items() if k in ['mse','rmse','mae','r2']},
        'dropped_features': dropped_features,
        'top_permutation_importance': perm_imp_df.head(10).to_dict(orient='records'),
        'top_feature_importance': feat_imp.head(10).to_dict(orient='records')
    }

    metrics_path = Path(MODEL_PATH).with_suffix('.metrics.json')
    save_artifacts(rf, X.columns.tolist(), metrics_to_save,
                   out_model_path=MODEL_PATH,
                   out_columns_path=COLUMNS_PATH,
                   out_metrics_path=metrics_path)

    print("=" * 50)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ")
    print(f"äº¤å‰éªŒè¯ RÂ² å¹³å‡å€¼: {scores.mean():.4f}")
    print(f"æµ‹è¯•é›† RÂ²: {final_metrics['r2']:.4f}")
    if dropped_features:
        print(f"ä»¥ä¸‹ç‰¹å¾å› ä¸ºä¸ç›®æ ‡è¿‡äºç›¸å…³ï¼Œå·²è¢«è‡ªåŠ¨ç§»é™¤: {dropped_features}")
    print("=" * 50)


if __name__ == "__main__":
    main()
